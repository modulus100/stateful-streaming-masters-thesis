This section provides results and future work that should provide deep knowledge
about systems performance.


\section{Summary}\label{sec:recap-of-the-research}
%First at all, it needs to be mentioned that periodic batch processing job
%is might not be that scalable and fault-tolerant as modern
%stream processing frameworks.
%Stream processing can replace and should replace solutions which require
%a continuous stream processing with a minimal latency.
%Proper configuration and replica size significantly reduces latency comparing
%to periodic batch processing solutions.
%However, it also helps batch processing to reduce network load.
%But having Kafka interface, a requirement in low latency and fault tolerance,
%stream processing solutions win.
Both prototypes based on the Apache Kafka and Apache Flink frameworks demonstrated robust capabilities in state restoration
during short-term replica failures.
However, several performance insights appeared in the distributed environment
while processing the same input data for all experiments.
In an experiment involving a cluster of 8 workers, the average recovery time to return to normal processing
after 2 workers failed was 143 seconds for Kafka Streams and 113 seconds for Apache Flink.
When the entire cluster of 8 workers gets killed, the average recovery time to return to
normal processing was 153 seconds for Kafka Streams and 114 seconds for Apache Flink.
For both experiments, Apache Flink has shown better performance, for the first is about 30 seconds
and for the second is 40 seconds.
The main reason behind this behavior is Apache Flink's ability to complete rebalancing faster and start processing of
incoming records sooner.
CPU metrics from the case study show that the Kafka Streams cluster experiences higher downtime.
The lag trend metric in this case study showed better performance for Apache Flink.
This means that, despite latency after rebalancing and state recovery,
Apache Flink processes incoming records with less latency for all experiments.
A significant difference was recorded when the entire cluster gets killed.


\section{Future work}\label{sec:future-work}
Such results just depict one of use cases, however, benchmarks could be significantly
extended with having set of additional configurations.
This research could be extended with additional configurations.

\begin{description}
    \item[JVM] Different Java versions should be able to show a performance difference especially with new Java 21
    garbage collector release.
    Both Apache Flink and Kafka Streams are JVM based frameworks.
    \item[State Backend] The main state backend for Kafka Streams is RocksDB. However, Apache Flink provides
    different state backend setups and RocksDB as well.
    \item[State Size] Different state size in a case of fault tolerance should bring more insights about frameworks
    for real production systems that use large states.
\end{description}

Another direction of benchmarking involves testing various failure scenarios that are common in production systems,
such as slow networking, disk backpressure, and running out of disk space.
That would help extend chaos engineering knowledge for the critical real-time systems.


